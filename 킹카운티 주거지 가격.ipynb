{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5c1ff69-9a1d-4c01-88e1-3a740ba2f53a",
   "metadata": {},
   "source": [
    "## 참고\n",
    "- 본 코드는 빅데이터분석기사 실기 작업형 2유형을 위한 연습용 코드임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e532c39-f12c-4960-b25f-8b9058be8076",
   "metadata": {},
   "outputs": [],
   "source": [
    "Main_name = 'kingcountyprice'\n",
    "\n",
    "trainData  = f'https://raw.githubusercontent.com/Datamanim/datarepo/main/{Main_name}/train.csv'\n",
    "testData  = f'https://raw.githubusercontent.com/Datamanim/datarepo/main/{Main_name}/test.csv'\n",
    "subData  = f'https://raw.githubusercontent.com/Datamanim/datarepo/main/{Main_name}/submission.csv'\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#데이터로드\n",
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv(trainData)\n",
    "test = pd.read_csv(testData)\n",
    "submission = pd.read_csv(subData)\n",
    "\n",
    "\n",
    "drop_col = ['id','date','zipcode','lat','long']\n",
    "\n",
    "train.drop(drop_col,axis=1,inplace=True)\n",
    "test.drop(drop_col,axis=1,inplace=True)\n",
    "\n",
    "y = train['price']\n",
    "X = train.iloc[:,1:]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X , y, test_size = 0.3,random_state = 42 )\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc_mm = MinMaxScaler()\n",
    "sc_ss = StandardScaler()\n",
    "\n",
    "# 1. MInMax로 했을 때\n",
    "X_train_mm = sc_mm.fit_transform(X_train)\n",
    "X_test_mm = sc_mm.transform(X_test)\n",
    "\n",
    "## dir(sklearn.ensemble) ##\n",
    "import sklearn\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor( random_state= 42 )      # parameter : n_estimators = 100, max_depth = 3 \n",
    "rf.fit(X_train, y_train)\n",
    "rf_y_pred = rf.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "print('RF r2_score: ',r2_score(y_test, rf_y_pred)) # RF r2_score:  0.7284506460848885\n",
    "\n",
    "\n",
    "# GradientBoostingRegressor / help(sklearn.ensemble.GradientBoostingRegressor)\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "gbr = GradientBoostingRegressor(random_state= 42)     # learning_rate(0.1 ~ 0,01 ), n_estimators(100 ), max_depth(defalut : 3), random_state , verbose(0 or 1)\n",
    "gbr.fit(X_train, y_train)\n",
    "gbr_y_pred = gbr.predict(X_test)\n",
    "print('gbr r2 score: ', r2_score(y_test, gbr_y_pred)) # 0.7171536002097245\n",
    "\n",
    "## dir(sklearn.linear_model) ##\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lrr = LinearRegression()\n",
    "lrr.fit(X_train, y_train)\n",
    "lrr_y_pred =lrr.predict(X_test) \n",
    "print('Linear Regression r2 score: ', r2_score(y_test, lrr_y_pred)) #  0.6545932706051483\n",
    "\n",
    "# Ridge\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "ridge = Ridge()\n",
    "ridge.fit(X_train, y_train)\n",
    "ridge_y_pred = ridge.predict(X_test)\n",
    "print('릿지 r2 score ', r2_score(y_test, ridge_y_pred)) # 0.6547560311779191\n",
    "\n",
    "# Lasso\n",
    "lasso = Lasso() # max_iter ,alpha\n",
    "lasso.fit(X_train, y_train)\n",
    "lasso_y_pred = lasso.predict(X_test)\n",
    "print('라쏘 r2 score', r2_score(y_test, lasso_y_pred)) #  0.6545965041603428\n",
    "\n",
    "\n",
    "## dir(xgboost) ##\n",
    "# xgboost - XGBRegressor\n",
    "from xgboost import XGBRFRegressor \n",
    "xgbrf = XGBRFRegressor(random_state =42)\n",
    "xgbrf.fit(X_train, y_train)\n",
    "xgbrf_y_pred = xgbrf.predict(X_test)\n",
    "print('xgbRF r2 score ', r2_score(y_test, xgbrf_y_pred)) # 0.5995687211119499\n",
    "\n",
    "# xgboost - XGBRegressor \n",
    "from xgboost import XGBRegressor\n",
    "xgb= XGBRegressor(random_state=42)# max_depth, learning_rate, n_estimators\n",
    "xgb.fit(X_train, y_train) \n",
    "xgb_y_pred = xgb.predict(X_test) \n",
    "print('xgb_reg r2 score', r2_score(y_test, xgb_y_pred)) 0.7176627781396154\n",
    "\n",
    "\n",
    "submission = rf.predict(test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8823b3b3-af83-4711-b567-42981536e25e",
   "metadata": {},
   "source": [
    "## 그리드서치 수행"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d8ae8d-0e00-4f7b-a6dc-fc3bd403a24e",
   "metadata": {},
   "source": [
    "### 그리드 서치 전"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42997ca-4e6f-4057-ba17-15c9901f675c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## # n_estimators 는 tree의 개수를 의미  \n",
    "## RandomForestRegressor \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor( random_state= 42 )      # parameter : n_estimators = 100, max_depth = 3 \n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# 결과 살펴보기 \n",
    "from sklearn.metrics import mean_squared_error \n",
    "from sklearn.metrics import mean_absolute_error \n",
    "import numpy as np \n",
    "\n",
    "print('MAE:', mean_absolute_error(y_test, y_pred)) \n",
    "\n",
    "print('MSE:', mean_squared_error(y_test, y_pred)) \n",
    "\n",
    "print('RMSE:', np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "\n",
    "print('R2:', r2_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efdb021-ffda-426e-a6d1-93a7712569bf",
   "metadata": {},
   "source": [
    "### 그리드서치 후"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fd7d9d-7996-4915-848a-6a2b25ad2a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [ {'n_estimators': [50,100,200], 'max_features':[2, 4, 6, 8]}, {'bootstrap': [False]}] \n",
    "\n",
    "RF_reg2 = RandomForestRegressor() \n",
    "\n",
    "grid_search = GridSearchCV(RF_reg2, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train) \n",
    "\n",
    "\n",
    "print('grid_search.best_params_', grid_search.best_params_) # 8 ,n_estimators : 200\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e31d6f-e8b0-4c0d-bc70-5424b31e3961",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = 200\n",
    "\n",
    "max_features = 8\n",
    "\n",
    "RF_reg = RandomForestRegressor(n_estimators=n_estimators, random_state=42, max_features=max_features) \n",
    "RF_reg.fit(X_train, y_train)\n",
    "y_pred = RF_reg.predict(X_test)\n",
    "\n",
    "print('## RandomForestRegressor > n_estimators:', n_estimators) \n",
    "\n",
    "print('MAE:', mean_absolute_error(y_test, y_pred)) \n",
    "\n",
    "print('MSE:', mean_squared_error(y_test, y_pred)) \n",
    "\n",
    "print('RMSE:', np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "\n",
    "print('R2 score ', r2_score(y_test, y_pred)) ## 0.72 -> 0.73 .. ...?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
